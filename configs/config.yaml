---
seed: 42

sync_bn: True

num_workers: 12
experiment_name: "2023-08-24"

train_image_path: ./data/widerface/train/images/
val_image_path: ./data/widerface/val/images/

train_annotation_path: ./data/widerface/train/images/label.json
val_annotation_path: ./data/widerface/val/images/label.json

num_classes: 2

model:
  type: models.network.RetinaFace
  name: mobilenet0.25
  pretrained: True
  return_layers: {"stage1": 1, "stage2": 2, "stage3": 3}
  in_channels: 32
  out_channels: 64


optimizer:
  type: torch.optim.SGD
  lr: 0.001
  weight_decay: 0.0005
  momentum: 0.9

trainer:
  type: pytorch_lightning.Trainer
  accelerator: "gpu"
  devices: [0]
  max_epochs: 150
  strategy: ddp
  accumulate_grad_batches: 1
  benchmark: True
  check_val_every_n_epoch: 5
  precision: 16
  profiler: "simple"

tester:
  type: pytorch_lightning.Trainer
  accelerator: "gpu"
  devices: [0]
  precision: 16

scheduler:
  type: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
  T_0: 10
  T_mult: 2

train_parameters:
  batch_size: 8
  rotate90: False

checkpoint_callback:
  type: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: "weights"
  monitor: val_loss
  verbose: True
  mode: max
  save_top_k: -1
  filename: "mobilenet0.25-{epoch:02d}-{val_loss:.2f}"

val_parameters:
  batch_size: 10
  iou_threshold: 0.4
  rotate90: False

loss:
  type: models.multibox_loss.MultiBoxLoss
  num_classes: 2
  overlap_thresh: 0.35
  prior_for_matching: True
  bkg_label: 0
  neg_mining: True
  neg_pos: 7
  neg_overlap: 0.35
  encode_target: False

prior_box:
  type: models.prior_box.priorbox
  min_sizes: [[10, 20], [32, 64], [128, 256]]
  steps: [8, 16, 32]
  clip: False

image_size: [640, 640]

loss_weights:
  localization: 2
  classification: 1
  landmarks: 1

test_parameters:
  variance: [0.1, 0.2]

train_aug:
  transform:
    __class_fullname__: albumentations.core.composition.Compose
    bbox_params: null
    keypoint_params: null
    p: 1
    transforms:
      - __class_fullname__: albumentations.augmentations.transforms.RandomBrightnessContrast
        always_apply: false
        brightness_limit: 0.125
        contrast_limit: [0.5, 1.5]
        p: 0.5
      - __class_fullname__: albumentations.augmentations.transforms.HueSaturationValue
        hue_shift_limit: 18
        val_shift_limit: 0
        p: 0.5
      - __class_fullname__: albumentations.augmentations.transforms.Resize
        height: 300
        width: 300
        p: 1
      - __class_fullname__: albumentations.augmentations.transforms.Normalize
        always_apply: false
        max_pixel_value: 255.0
        mean:
          - 0.485
          - 0.456
          - 0.406
        p: 1
        std:
          - 0.229
          - 0.224
          - 0.225

val_aug:
  transform:
    __class_fullname__: albumentations.core.composition.Compose
    bbox_params: null
    keypoint_params: null
    p: 1
    transforms:
      - __class_fullname__: albumentations.augmentations.transforms.Resize
        height: 300
        width: 300
        p: 1
      - __class_fullname__: albumentations.augmentations.transforms.Normalize
        always_apply: false
        max_pixel_value: 255.0
        mean:
          - 0.485
          - 0.456
          - 0.406
        p: 1
        std:
          - 0.229
          - 0.224
          - 0.225

test_aug:
  transform:
    __class_fullname__: albumentations.core.composition.Compose
    bbox_params: null
    keypoint_params: null
    p: 1
    transforms:
      - __class_fullname__: albumentations.augmentations.transforms.Normalize
        always_apply: false
        max_pixel_value: 255.0
        mean:
          - 0.485
          - 0.456
          - 0.406
        p: 1
        std:
          - 0.229
          - 0.224
          - 0.225