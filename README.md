# RetinaFace
## What's new
 - Pre-release training dataset
 - Demo mobilenet-0.25 backbone with openvino api 2.0 library
 - Export model with input shape is (640,640)

## Project Structure

The directory structure of new project looks like this:

```
├── .github                   <- Github Actions workflows
│
├── configs                   <- Hydra configs
│   ├── callbacks                <- Callbacks configs
│   ├── data                     <- Data configs
│   ├── debug                    <- Debugging configs
│   ├── experiment               <- Experiment configs
│   ├── extras                   <- Extra utilities configs
│   ├── hparams_search           <- Hyperparameter search configs
│   ├── hydra                    <- Hydra configs
│   ├── local                    <- Local configs
│   ├── logger                   <- Logger configs
│   ├── model                    <- Model configs
│   ├── paths                    <- Project paths configs
│   ├── trainer                  <- Trainer configs
│   │
│   ├── eval.yaml             <- Main config for evaluation
│   └── train.yaml            <- Main config for training
│
├── data                   <- Project data
│
├── logs                   <- Logs generated by hydra and lightning loggers
│
├── notebooks              <- Jupyter notebooks. Naming convention is a number (for ordering),
│                             the creator's initials, and a short `-` delimited description,
│                             e.g. `1.0-jqp-initial-data-exploration.ipynb`.
│
├── scripts                <- Shell scripts
│
├── src                    <- Source code
│   ├── data                     <- Data scripts
│   ├── models                   <- Model scripts
│   ├── utils                    <- Utility scripts
│   │
│   ├── eval.py                  <- Run evaluation
│   └── train.py                 <- Run training
│
├── tests                  <- Tests of any kind
│
├── .env.example              <- Example of file for storing private environment variables
├── .gitignore                <- List of files ignored by git
├── .pre-commit-config.yaml   <- Configuration of pre-commit hooks for code formatting
├── .project-root             <- File for inferring the position of project root directory
├── environment.yaml          <- File for installing conda environment
├── Makefile                  <- Makefile with commands like `make train` or `make test`
├── pyproject.toml            <- Configuration options for testing and linting
├── requirements.txt          <- File for installing python dependencies
├── setup.py                  <- File for installing project as a package
└── README.md
```

## Dependencies
- Ubuntu18.04
- Python3.8
- torch==2.0.1
- torchmetrics==1.0.3
- onnx==1.14.0
- onnxruntime==1.11.0
- onnxsim==0.4.33
- openvino==2023.0.1
- lightning==2.0.0
- wandb==0.15.8
- opencv-python==4.5.2.52

## Experiment
### Widerface
 - Datasets: Widerface,...

 Backbone|Easy|Medium|Hard
------|--------|----------|--------
Retinaface-Mobilenet-0.25(our)  |||

## Performance

Backbone|parameter(M)|flop(M) 
------|--------|----------
Retinaface-Mobilenet-0.25(our)  |0.426|193.921

## Quickstart
- [Installation](#installation)
- [Training](#training)
- [Testing](#testing)
- [Inference](#inference)

### Installation
#### Create new environment
1. git clone this repository
2. conda create --name env python=3.8
3. pip3 install -r requirements.txt

#### Prepare Dataset
1. The dataset directory as follows:
```Shell
ln -s [path of the target file/directory] ./data/widerface
```

2. Annotation template
```Shell
[
  {
    "file_name": "0--Parade/0_Parade_marchingband_1_849.jpg",
    "annotations": [
      {
        "bbox": [
          449,
          330,
          571,
          720
        ],
        "landmarks": [
          [
            488.906,
            373.643
          ],
          [
            542.089,
            376.442
          ],
          [
            515.031,
            412.83
          ],
          [
            485.174,
            425.893
          ],
          [
            538.357,
            431.491
          ]
        ]
      }
    ]
  },
]
```

### Training

1. Before training, you can check network configuration (e.g. batch_size, min_sizes and steps etc..) in ``data/config.py and train.py``.

2. Train the model using WIDER FACE:
  ```Shell
  export TRAIN_IMAGE_PATH=<path to train images>
  export VAL_IMAGE_PATH=<path to validation images>
  export TRAIN_LABEL_PATH=<path to train annotations>
  export VAL_LABEL_PATH=<path to validation annotations>

  python src/train.py -c ./configs/config.yaml or bash scripts/train.sh
  ```

### Testing
#### Test data module
```Shell
python -m unittest tests.test_datamodules
```
#### Test train module
```Shell
python -m unittest tests.test_train
```

### Inference
1. Generate onnx file
```Shell
python src/export.py -c ./configs/config.yaml -p ./weights/mobilenet0.25_Final.pth
```
2. Optimize the onnx file
```Shell
python -m onnxruntime.tools.convert_onnx_models_to_ort weights/mobilenet0.25_Final.onnx --save_optimized_onnx_model --optimization_style Fixed
```
3. Convert onnx to openvino
```Shell
mo --input_model weights/mobilenet0.25_Final.optimized.onnx --output_dir weights/openvino/retinaface
```
4. Run inference for webcam demo

- Run the inference with pytorch
```Shell
python src/inference_pytorch.py -c ./configs/config.yaml -p ./weights/mobilenet0.25_Final.pth
```
- Run the inference with openvino (best choice for edge devices)
```Shell
python src/inference_openvino.py -p ./weights/openvino/retinaface/mobilenet0.25_Final.optimized.xml
```